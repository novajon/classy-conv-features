{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Other model tests\n",
    "\n",
    "\n",
    "- from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "- from sklearn.neighbors import KNeighborsClassifier\n",
    "- from sklearn.linear_model import LogisticRegression\n",
    "- import xgboost as xgb\n",
    "- from sklearn.tree import DecisionTreeClassifier\n",
    "\n",
    "\n",
    "- Ensemble methods\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from scipy import stats\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "training_src=[]\n",
    "test_src = []\n",
    "validation_src = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/*.txt\")\n",
    "for file in file_list:\n",
    "    f_type = file.split(\"_pred_\")[-1].split(\"_\")[0]\n",
    "    if f_type == \"train\":\n",
    "        training_src.append(file)\n",
    "    elif f_type == \"val\":\n",
    "        validation_src.append(file)\n",
    "    elif f_type == \"test\":\n",
    "        test_src.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\ntraining_src = []\\nvalidation_src = []\\ntest_src = []\\nfor x in range(0,100):\\n    training_src.append(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/{}_pred_train_with_target_cut_data.txt\".format(x))\\n    validation_src.append(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/{}_pred_val_with_target_cut_data.txt\".format(x))\\n    test_src.append(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/{}_pred_test_with_target_cut_data.txt\".format(x))\\n\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "\"\"\"\n",
    "training_src = []\n",
    "validation_src = []\n",
    "test_src = []\n",
    "for x in range(0,100):\n",
    "    training_src.append(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/{}_pred_train_with_target_cut_data.txt\".format(x))\n",
    "    validation_src.append(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/{}_pred_val_with_target_cut_data.txt\".format(x))\n",
    "    test_src.append(\"351_Data/CIFAR_100_filtered/Intermediate Data from Conv layers/{}_pred_test_with_target_cut_data.txt\".format(x))\n",
    "\n",
    "\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_data(src):\n",
    "    with open(src, 'r') as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def treat_data(data_string):\n",
    "    data_string = data_string.replace(\"]\", \"\")\n",
    "    data_string = data_string.replace(\" \", \"\")\n",
    "    data_split = data_string.split(\"[\")\n",
    "    data_split = [(d.split(\",\")) for d in data_split]\n",
    "    data_split_clean = [d[:-1] for d in data_split[:-1]]\n",
    "    data_split_clean.append(data_split[-1])\n",
    "    data_split_clean = [d for d in data_split_clean if d]\n",
    "    return data_split_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    inp = []\n",
    "    target = []\n",
    "    for d in data:\n",
    "        inp.append([float(x) for x in d[:-1]])\n",
    "        target.append(float(d[-1]))\n",
    "    inp = np.array(inp)\n",
    "    target = np.array(target)\n",
    "    return inp,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_source (src):\n",
    "    data_string = read_data(src)\n",
    "    data_split = treat_data(data_string)\n",
    "    return split_data(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    y_pred = model.predict(data[0])\n",
    "    try: predictions = [round(value) for value in y_pred]\n",
    "    except: predictions = [np.argmax(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    accuracy = accuracy_score(data[1], predictions)\n",
    "    return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_measures(measure, data_type=\"data\", measure_name=\"Accuracy\"):\n",
    "    return \"%s in %s: %.2f%%\" % (measure_name, data_type, measure * 100.0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def get_data_from_sources (training_src, test_src, validation_src=\"\"):\n",
    "    train = get_data_from_source(training_src)\n",
    "    test = get_data_from_source(test_src)\n",
    "    try:\n",
    "        if validation_src !=\"\":\n",
    "            val = get_data_from_source(validation_src)\n",
    "        else:\n",
    "            inp_test, inp_val, target_test, target_val = train_test_split(*test)\n",
    "            test = (inp_test, target_test)\n",
    "            val = (inp_val, target_val)\n",
    "    except: \n",
    "        inp_test, inp_val, target_test, target_val = train_test_split(*test)\n",
    "        test = (inp_test, target_test)\n",
    "        val = (inp_val, target_val)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "val_data = []\n",
    "\n",
    "ind = 0\n",
    "for ind, _ in enumerate(training_src):\n",
    "    if ind>=len(validation_src):\n",
    "        val_src = \"\"\n",
    "    else:\n",
    "        val_src = validation_src[ind]\n",
    "    train, val, test = get_data_from_sources(training_src[ind], test_src[ind], val_src)\n",
    "    train_data.append(train)\n",
    "    test_data.append(test)\n",
    "    val_data.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "num_classes = int(max(train_data[0][1])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "mlp_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(2048,)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2048,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(num_classes, input_shape=(2048,)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "for model in mlp_models:\n",
    "    \n",
    "epochs=5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Crossvalidation of neural networks done using mlp_models with multiple model architectures in list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_candidates = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "svm_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  # {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rfe_candidates = [\n",
    "  {'n_estimators': [10, 100, 1000], 'criterion': ['gini', \"entropy\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "adb_candidates = [\n",
    "  {'n_estimators': [10, 100, 1000], 'learning_rate': [1.0, 0.5, 0.1], 'algorithm':[\"SAMME.R\", \"SAMME\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 110,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "gbc_candidates = [\n",
    "  {'n_estimators': [10, 100, 1000], 'learning_rate': [0.05, 0.1, 0.5], 'criterion':[\"friedman_mse\", \"mae\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 111,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lr_candidates= [\n",
    "    {'penalty': [\"l2\", \"l5\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dtc_candidates= [\n",
    "    {'criterion': [\"l1\", \"l2\"], 'splitter':['best']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 113,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "xgbc_candidates = [\n",
    "    {\n",
    "        'max_depth':[10], 'learning_rate':[0.1], 'n_estimators':[1000]     # objective, booster\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "parameter_candidates [\"svm\"] = svm_candidates\n",
    "parameter_candidates[\"rfe\"] = rfe_candidates\n",
    "parameter_candidates [\"adb\"] = adb_candidates\n",
    "parameter_candidates[\"gbc\"] = gbc_candidates\n",
    "parameter_candidates[\"lr\"] = lr_candidates\n",
    "parameter_candidates [\"dtc\"] = dtc_candidates\n",
    "parameter_candidates[\"xgbc\"] = xgbc_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RandomForestClassifier()\n",
    "adb = AdaBoostClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "lr = LogisticRegression()\n",
    "dtc = DecisionTreeClassifier()#\n",
    "xgbc = XGBClassifier()\n",
    "svc = svm.SVC()\n",
    "# Genetic Programming-based\n",
    "\n",
    "# benchmark_models = {\"rfe\":rfe, \"xgbc\":xgbc, \"adb\":adb, \"gbc\":gbc, \"lr\":lr, \"dtc\":dtc, \"svm\":svc}\n",
    "benchmark_models = {\"adb\":adb, \"gbc\":gbc, \"lr\":lr, \"dtc\":dtc, \"svm\":svc}\n",
    "for x in range(len(mlp_models)):\n",
    "    benchmark_models[\"mlp_{}\".format(x)] = mlp_models[x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def grid_search_model(benchmark_models, parameter_candidates, train, val, test):\n",
    "    for model_key in benchmark_models.keys():\n",
    "        model = benchmark_models[model_key]\n",
    "        print ((\" Model: \" + str(model_key)+ \" \").center(30, '#'))\n",
    "        try:\n",
    "            t0 = time.time()\n",
    "            clf = GridSearchCV(estimator=model, param_grid=parameter_candidates[model_key], n_jobs=-1, cv=4)\n",
    "            clf.fit (*train)\n",
    "            t1 = time.time()\n",
    "            total = t1-t0\n",
    "            print(\"Training Time: {}\".format(total))\n",
    "            print (clf.score(*train))\n",
    "            print (clf.score(*val))\n",
    "            print (clf.score(*test))\n",
    "            print (clf.best_estimator_)\n",
    "            benchmark_models[model_key] = clf.best_estimator_\n",
    "        except ValueError:\n",
    "            history = model.fit(train[0], to_categorical(train[1]), epochs = epochs, validation_data = (val[0], to_categorical(val[1])))\n",
    "            benchmark_models[model_key] = model\n",
    "    return benchmark_models\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Model: adb #########\n"
     ]
    }
   ],
   "source": [
    "grid_search_model(benchmark_models, parameter_candidates, train_data[0], val_data[0], test_data[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 499,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_model (benchmark_models, train, val):\n",
    "    for model in benchmark_models.values():\n",
    "        try: model.fit(*train)\n",
    "        except ValueError:\n",
    "            history = model.fit(train[0], to_categorical(train[1]), epochs = epochs, validation_data = (val[0], to_categorical(val[1])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def evaluate_model(benchmark_models, train, val, test):\n",
    "    for model_key in benchmark_models.keys():\n",
    "        try:\n",
    "            model = benchmark_models[model_key]\n",
    "            train_eval = evaluate(model,train)\n",
    "            val_eval = evaluate(model, val)\n",
    "            test_eval = evaluate(model, test)\n",
    "            print ((\" Model: \" + str(model_key)+ \" \").center(30, '#'))\n",
    "            print (get_measures(train_eval, \"Train\", \"Accuracy\"))\n",
    "            print (get_measures(val_eval, \"Validation\", \"Accuracy\"))    \n",
    "            print (get_measures(test_eval, \"Test\", \"Accuracy\"))    \n",
    "        except Exception as ex:\n",
    "            template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "            message = template.format(type(ex).__name__, ex.args)\n",
    "            print (message)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def train_and_evaluate_model (benchchmark_models, train, val, test, model_iterations=10):\n",
    "    model_unseen_measures = {}\n",
    "    for model_key in benchmark_models.keys():\n",
    "        model_unseen_measures[model_key] = []\n",
    "        for i in range(model_iterations):\n",
    "            try:\n",
    "                model = benchmark_models[model_key]\n",
    "                try: \n",
    "                    model.fit(*train)\n",
    "                except ValueError:\n",
    "                    history = model.fit(train[0], to_categorical(train[1]), epochs = epochs, validation_data = (val[0], to_categorical(val[1])))\n",
    "                train_eval = evaluate(model,train)\n",
    "                val_eval = evaluate(model, val)\n",
    "                test_eval = evaluate(model, test)\n",
    "                model_unseen_measures[model_key].append(test_eval)\n",
    "                \n",
    "                print ((\" Model: \" + str(model_key)+ \" \").center(30, '#'))\n",
    "                print (get_measures(train_eval, \"Train\", \"Accuracy\"))\n",
    "                print (get_measures(val_eval, \"Validation\", \"Accuracy\"))    \n",
    "                print (get_measures(test_eval, \"Test\", \"Accuracy\"))\n",
    "            except Exception as ex:\n",
    "                template = \"An exception of type {0} occurred. Arguments:\\n{1!r}\"\n",
    "                message = template.format(type(ex).__name__, ex.args)\n",
    "                print (message)\n",
    "                model_unseen_measures[model_key].append(\"NaN\")\n",
    "\n",
    "    return model_unseen_measures"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_results (model_results):\n",
    "    p_values = {}\n",
    "    for m_key in model_results.keys():\n",
    "        cp_values = []\n",
    "        ref_model = model_results[m_key]\n",
    "        for m2_key in model_results.keys():\n",
    "            comp_model = model_results[m2_key]\n",
    "            # pv = test_significance(ref_model, comp_model)\n",
    "            statistic, p_value = stats.ttest_ind(ref_model, comp_model)\n",
    "            if statistic >= 0:\n",
    "                cp_values.append(p_value)\n",
    "            else:\n",
    "                cp_values.append(-p_value)\n",
    "        p_values [m_key] = cp_values\n",
    "    pd_res = pd.DataFrame(p_values, index=model_results.keys())\n",
    "    pd_res = pd_res[list(model_results.keys())]\n",
    "    return pd_res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "____________________________________________________________\n",
      "############################################################\n",
      "##################### Dataset Index: 0 #####################\n",
      "############################################################\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.84%\n",
      "Accuracy in Validation: 10.24%\n",
      "Accuracy in Test: 52.30%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.81%\n",
      "Accuracy in Validation: 11.52%\n",
      "Accuracy in Test: 52.00%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.79%\n",
      "Accuracy in Validation: 9.84%\n",
      "Accuracy in Test: 52.90%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.68%\n",
      "Accuracy in Validation: 8.32%\n",
      "Accuracy in Test: 50.90%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.81%\n",
      "Accuracy in Validation: 8.56%\n",
      "Accuracy in Test: 50.80%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.84%\n",
      "Accuracy in Validation: 10.96%\n",
      "Accuracy in Test: 51.80%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.71%\n",
      "Accuracy in Validation: 11.20%\n",
      "Accuracy in Test: 51.20%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.79%\n",
      "Accuracy in Validation: 10.80%\n",
      "Accuracy in Test: 52.10%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.63%\n",
      "Accuracy in Validation: 11.84%\n",
      "Accuracy in Test: 50.70%\n",
      "######### Model: rfe #########\n",
      "Accuracy in Train: 99.76%\n",
      "Accuracy in Validation: 12.00%\n",
      "Accuracy in Test: 51.10%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######## Model: xgbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 70.50%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: adb #########\n",
      "Accuracy in Train: 40.53%\n",
      "Accuracy in Validation: 9.12%\n",
      "Accuracy in Test: 33.90%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.24%\n",
      "Accuracy in Test: 69.00%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.92%\n",
      "Accuracy in Test: 69.00%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.92%\n",
      "Accuracy in Test: 68.90%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.84%\n",
      "Accuracy in Test: 69.00%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.64%\n",
      "Accuracy in Test: 69.10%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.08%\n",
      "Accuracy in Test: 69.00%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.44%\n",
      "Accuracy in Test: 69.10%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.44%\n",
      "Accuracy in Test: 69.10%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.92%\n",
      "Accuracy in Test: 69.00%\n",
      "######### Model: gbc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.16%\n",
      "Accuracy in Test: 69.10%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: lr ##########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.80%\n",
      "Accuracy in Test: 73.00%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.96%\n",
      "Accuracy in Test: 38.60%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.20%\n",
      "Accuracy in Test: 39.70%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.12%\n",
      "Accuracy in Test: 38.30%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.48%\n",
      "Accuracy in Test: 40.50%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.60%\n",
      "Accuracy in Test: 40.40%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.56%\n",
      "Accuracy in Test: 38.00%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.32%\n",
      "Accuracy in Test: 38.90%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.92%\n",
      "Accuracy in Test: 37.80%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.68%\n",
      "Accuracy in Test: 38.80%\n",
      "######### Model: dtc #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.84%\n",
      "Accuracy in Test: 39.10%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "######### Model: svm #########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.92%\n",
      "Accuracy in Test: 76.50%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.8148 - acc: 0.7347 - val_loss: 4.0640 - val_acc: 0.0824\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.1461 - acc: 0.9563 - val_loss: 4.1838 - val_acc: 0.0888\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0664 - acc: 0.9835 - val_loss: 4.2793 - val_acc: 0.0896\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0348 - acc: 0.9941 - val_loss: 4.3550 - val_acc: 0.0968\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0256 - acc: 0.9979 - val_loss: 4.4615 - val_acc: 0.0936\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 9.36%\n",
      "Accuracy in Test: 72.20%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0190 - acc: 0.9968 - val_loss: 4.5088 - val_acc: 0.0928\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.0127 - acc: 0.9987 - val_loss: 4.5521 - val_acc: 0.0952\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0083 - acc: 1.0000 - val_loss: 4.6274 - val_acc: 0.0920\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0073 - acc: 0.9997 - val_loss: 4.6638 - val_acc: 0.1040\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0075 - acc: 0.9997 - val_loss: 4.7050 - val_acc: 0.1072\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.72%\n",
      "Accuracy in Test: 72.20%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0047 - acc: 1.0000 - val_loss: 4.7137 - val_acc: 0.1080\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0042 - acc: 1.0000 - val_loss: 4.7500 - val_acc: 0.1040\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 0.0046 - acc: 0.9997 - val_loss: 4.8074 - val_acc: 0.1000\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0035 - acc: 1.0000 - val_loss: 4.8747 - val_acc: 0.1024\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0030 - acc: 1.0000 - val_loss: 4.9064 - val_acc: 0.1032\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.32%\n",
      "Accuracy in Test: 73.00%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0028 - acc: 0.9997 - val_loss: 4.9510 - val_acc: 0.1096\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0026 - acc: 1.0000 - val_loss: 4.9680 - val_acc: 0.1048\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0027 - acc: 0.9995 - val_loss: 5.0131 - val_acc: 0.1096\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 5.0402 - val_acc: 0.1056\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.0567 - val_acc: 0.1104\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.04%\n",
      "Accuracy in Test: 72.90%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0015 - acc: 1.0000 - val_loss: 5.0989 - val_acc: 0.1120\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.1285 - val_acc: 0.1136\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.1391 - val_acc: 0.1080\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 5.1550 - val_acc: 0.1096\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 0.0018 - acc: 1.0000 - val_loss: 5.2354 - val_acc: 0.1088\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.88%\n",
      "Accuracy in Test: 72.40%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 5.2672 - val_acc: 0.1088\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 5.3028 - val_acc: 0.1120\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 7.7515e-04 - acc: 1.0000 - val_loss: 5.3137 - val_acc: 0.1120\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 9.6052e-04 - acc: 1.0000 - val_loss: 5.3264 - val_acc: 0.1120\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 7.0529e-04 - acc: 1.0000 - val_loss: 5.3344 - val_acc: 0.1136\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.36%\n",
      "Accuracy in Test: 72.50%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 7s 2ms/step - loss: 5.9189e-04 - acc: 1.0000 - val_loss: 5.3524 - val_acc: 0.1128\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 5.2911e-04 - acc: 1.0000 - val_loss: 5.3810 - val_acc: 0.1144\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 4.5662e-04 - acc: 1.0000 - val_loss: 5.3884 - val_acc: 0.1144\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 5.0257e-04 - acc: 1.0000 - val_loss: 5.4167 - val_acc: 0.1152\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 5.9818e-04 - acc: 1.0000 - val_loss: 5.4394 - val_acc: 0.1128\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.28%\n",
      "Accuracy in Test: 73.00%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 3.8524e-04 - acc: 1.0000 - val_loss: 5.4537 - val_acc: 0.1128\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 3.8246e-04 - acc: 1.0000 - val_loss: 5.4718 - val_acc: 0.1136\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 3.4403e-04 - acc: 1.0000 - val_loss: 5.5022 - val_acc: 0.1160\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 4.4266e-04 - acc: 1.0000 - val_loss: 5.5507 - val_acc: 0.1104\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 3.4354e-04 - acc: 1.0000 - val_loss: 5.5646 - val_acc: 0.1064\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.64%\n",
      "Accuracy in Test: 73.40%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 3.1032e-04 - acc: 1.0000 - val_loss: 5.5970 - val_acc: 0.1088\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 3.5407e-04 - acc: 1.0000 - val_loss: 5.6224 - val_acc: 0.1080\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 3.0219e-04 - acc: 1.0000 - val_loss: 5.6313 - val_acc: 0.1080\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.9683e-04 - acc: 1.0000 - val_loss: 5.6371 - val_acc: 0.1088\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 2.1118e-04 - acc: 1.0000 - val_loss: 5.6551 - val_acc: 0.1088\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 10.88%\n",
      "Accuracy in Test: 73.20%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 2.0199e-04 - acc: 1.0000 - val_loss: 5.6638 - val_acc: 0.1088\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.7762e-04 - acc: 1.0000 - val_loss: 5.6962 - val_acc: 0.1096\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 2.0128e-04 - acc: 1.0000 - val_loss: 5.7172 - val_acc: 0.1112\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 9s 2ms/step - loss: 1.6781e-04 - acc: 1.0000 - val_loss: 5.7358 - val_acc: 0.1096\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 8s 2ms/step - loss: 1.6509e-04 - acc: 1.0000 - val_loss: 5.7691 - val_acc: 0.1128\n",
      "######## Model: mlp_0 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 11.28%\n",
      "Accuracy in Test: 72.50%\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 1.3011 - acc: 0.5811 - val_loss: 4.1749 - val_acc: 0.0984\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.4005 - acc: 0.8749 - val_loss: 4.2026 - val_acc: 0.1128\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.2037 - acc: 0.9435 - val_loss: 4.2839 - val_acc: 0.1112\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.1241 - acc: 0.9667 - val_loss: 4.3834 - val_acc: 0.1160\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0849 - acc: 0.9816 - val_loss: 4.4042 - val_acc: 0.1240\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.40%\n",
      "Accuracy in Test: 74.40%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0569 - acc: 0.9888 - val_loss: 4.4150 - val_acc: 0.1224\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0487 - acc: 0.9904 - val_loss: 4.4212 - val_acc: 0.1248\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0363 - acc: 0.9955 - val_loss: 4.4739 - val_acc: 0.1224\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0284 - acc: 0.9963 - val_loss: 4.4715 - val_acc: 0.1264\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0238 - acc: 0.9979 - val_loss: 4.5137 - val_acc: 0.1200\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.00%\n",
      "Accuracy in Test: 75.20%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0197 - acc: 0.9973 - val_loss: 4.5490 - val_acc: 0.1232\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0150 - acc: 0.9992 - val_loss: 4.5494 - val_acc: 0.1248\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0134 - acc: 0.9984 - val_loss: 4.5698 - val_acc: 0.1248\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0148 - acc: 0.9979 - val_loss: 4.5449 - val_acc: 0.1264\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0110 - acc: 0.9989 - val_loss: 4.5853 - val_acc: 0.1224\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.24%\n",
      "Accuracy in Test: 74.30%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0108 - acc: 0.9984 - val_loss: 4.6136 - val_acc: 0.1232\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0082 - acc: 0.9995 - val_loss: 4.5957 - val_acc: 0.1248\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0080 - acc: 0.9989 - val_loss: 4.5903 - val_acc: 0.1296\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0069 - acc: 0.9997 - val_loss: 4.6210 - val_acc: 0.1304\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 4.6709 - val_acc: 0.1320\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.20%\n",
      "Accuracy in Test: 74.90%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0057 - acc: 0.9992 - val_loss: 4.6672 - val_acc: 0.1288\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0045 - acc: 0.9997 - val_loss: 4.6773 - val_acc: 0.1288\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0059 - acc: 0.9992 - val_loss: 4.6881 - val_acc: 0.1384\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0048 - acc: 1.0000 - val_loss: 4.7155 - val_acc: 0.1392\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - ETA: 0s - loss: 0.0038 - acc: 1.000 - 4s 960us/step - loss: 0.0038 - acc: 1.0000 - val_loss: 4.7400 - val_acc: 0.1352\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.52%\n",
      "Accuracy in Test: 74.30%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0040 - acc: 0.9997 - val_loss: 4.7550 - val_acc: 0.1360\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0031 - acc: 0.9997 - val_loss: 4.7598 - val_acc: 0.1336\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 5s 1ms/step - loss: 0.0027 - acc: 1.0000 - val_loss: 4.7645 - val_acc: 0.1352\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0029 - acc: 1.0000 - val_loss: 4.7919 - val_acc: 0.1368\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 971us/step - loss: 0.0032 - acc: 0.9997 - val_loss: 4.7992 - val_acc: 0.1392\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.92%\n",
      "Accuracy in Test: 74.40%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0029 - acc: 0.9997 - val_loss: 4.7489 - val_acc: 0.1384\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0034 - acc: 0.9992 - val_loss: 4.7279 - val_acc: 0.1344\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0024 - acc: 1.0000 - val_loss: 4.7500 - val_acc: 0.1336\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0026 - acc: 0.9995 - val_loss: 4.7707 - val_acc: 0.1352\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0026 - acc: 0.9997 - val_loss: 4.8452 - val_acc: 0.1392\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.92%\n",
      "Accuracy in Test: 74.30%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 983us/step - loss: 0.0030 - acc: 0.9995 - val_loss: 4.9023 - val_acc: 0.1392\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0019 - acc: 1.0000 - val_loss: 4.9174 - val_acc: 0.1352\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0014 - acc: 1.0000 - val_loss: 4.9159 - val_acc: 0.1352\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0013 - acc: 1.0000 - val_loss: 4.9304 - val_acc: 0.1344\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 4.9214 - val_acc: 0.1368\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.68%\n",
      "Accuracy in Test: 74.60%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 3s 926us/step - loss: 0.0016 - acc: 0.9997 - val_loss: 4.9382 - val_acc: 0.1384\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0016 - acc: 0.9997 - val_loss: 4.9698 - val_acc: 0.1392\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0010 - acc: 1.0000 - val_loss: 4.9584 - val_acc: 0.1392\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0013 - acc: 0.9997 - val_loss: 4.9683 - val_acc: 0.1384\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0012 - acc: 0.9997 - val_loss: 5.0192 - val_acc: 0.1336\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.36%\n",
      "Accuracy in Test: 73.80%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 0.0017 - acc: 0.9995 - val_loss: 5.0380 - val_acc: 0.1392\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 9.6981e-04 - acc: 1.0000 - val_loss: 5.0510 - val_acc: 0.1392\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 8.7622e-04 - acc: 0.9997 - val_loss: 5.1179 - val_acc: 0.1336\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 4s 1ms/step - loss: 9.3834e-04 - acc: 1.0000 - val_loss: 5.0946 - val_acc: 0.1336\n",
      "Epoch 5/5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3750/3750 [==============================] - 4s 1ms/step - loss: 9.8646e-04 - acc: 1.0000 - val_loss: 5.1229 - val_acc: 0.1392\n",
      "######## Model: mlp_1 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.92%\n",
      "Accuracy in Test: 75.10%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 1s 204us/step - loss: 1.9321 - acc: 0.3645 - val_loss: 3.8042 - val_acc: 0.1256\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.8955 - acc: 0.7205 - val_loss: 3.8351 - val_acc: 0.1232\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.5673 - acc: 0.8424 - val_loss: 3.8678 - val_acc: 0.1264\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.4010 - acc: 0.9048 - val_loss: 3.8927 - val_acc: 0.1232\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.3015 - acc: 0.9365 - val_loss: 3.9182 - val_acc: 0.1296\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 95.20%\n",
      "Accuracy in Validation: 12.96%\n",
      "Accuracy in Test: 68.90%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 74us/step - loss: 0.2354 - acc: 0.9592 - val_loss: 3.9299 - val_acc: 0.1280\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 78us/step - loss: 0.1884 - acc: 0.9723 - val_loss: 3.9544 - val_acc: 0.1272\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 75us/step - loss: 0.1543 - acc: 0.9808 - val_loss: 3.9796 - val_acc: 0.1288\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.1283 - acc: 0.9885 - val_loss: 4.0004 - val_acc: 0.1280\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 75us/step - loss: 0.1081 - acc: 0.9925 - val_loss: 4.0205 - val_acc: 0.1288\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 99.52%\n",
      "Accuracy in Validation: 12.88%\n",
      "Accuracy in Test: 72.60%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 75us/step - loss: 0.0922 - acc: 0.9955 - val_loss: 4.0439 - val_acc: 0.1272\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.0795 - acc: 0.9976 - val_loss: 4.0616 - val_acc: 0.1288\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.0691 - acc: 0.9987 - val_loss: 4.0855 - val_acc: 0.1312\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.0605 - acc: 0.9997 - val_loss: 4.1028 - val_acc: 0.1328\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.0535 - acc: 1.0000 - val_loss: 4.1216 - val_acc: 0.1336\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.36%\n",
      "Accuracy in Test: 73.50%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 75us/step - loss: 0.0475 - acc: 1.0000 - val_loss: 4.1418 - val_acc: 0.1336\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 77us/step - loss: 0.0424 - acc: 1.0000 - val_loss: 4.1618 - val_acc: 0.1304\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.0380 - acc: 1.0000 - val_loss: 4.1832 - val_acc: 0.1320\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.0343 - acc: 1.0000 - val_loss: 4.2000 - val_acc: 0.1328\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.0310 - acc: 1.0000 - val_loss: 4.2169 - val_acc: 0.1328\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.28%\n",
      "Accuracy in Test: 73.60%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.0282 - acc: 1.0000 - val_loss: 4.2347 - val_acc: 0.1304\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.0257 - acc: 1.0000 - val_loss: 4.2532 - val_acc: 0.1312\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 79us/step - loss: 0.0235 - acc: 1.0000 - val_loss: 4.2712 - val_acc: 0.1304\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 76us/step - loss: 0.0216 - acc: 1.0000 - val_loss: 4.2882 - val_acc: 0.1296\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 78us/step - loss: 0.0198 - acc: 1.0000 - val_loss: 4.3055 - val_acc: 0.1288\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.88%\n",
      "Accuracy in Test: 73.70%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 96us/step - loss: 0.0183 - acc: 1.0000 - val_loss: 4.3231 - val_acc: 0.1304\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 103us/step - loss: 0.0169 - acc: 1.0000 - val_loss: 4.3344 - val_acc: 0.1296\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 109us/step - loss: 0.0156 - acc: 1.0000 - val_loss: 4.3536 - val_acc: 0.1288\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 107us/step - loss: 0.0144 - acc: 1.0000 - val_loss: 4.3705 - val_acc: 0.1296\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 105us/step - loss: 0.0134 - acc: 1.0000 - val_loss: 4.3885 - val_acc: 0.1296\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 12.96%\n",
      "Accuracy in Test: 73.90%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 106us/step - loss: 0.0125 - acc: 1.0000 - val_loss: 4.4045 - val_acc: 0.1312\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 107us/step - loss: 0.0116 - acc: 1.0000 - val_loss: 4.4227 - val_acc: 0.1328\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 105us/step - loss: 0.0108 - acc: 1.0000 - val_loss: 4.4407 - val_acc: 0.1336\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 104us/step - loss: 0.0101 - acc: 1.0000 - val_loss: 4.4569 - val_acc: 0.1344\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 106us/step - loss: 0.0094 - acc: 1.0000 - val_loss: 4.4738 - val_acc: 0.1344\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.44%\n",
      "Accuracy in Test: 73.60%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 107us/step - loss: 0.0088 - acc: 1.0000 - val_loss: 4.4922 - val_acc: 0.1336\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 102us/step - loss: 0.0082 - acc: 1.0000 - val_loss: 4.5086 - val_acc: 0.1328\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 104us/step - loss: 0.0077 - acc: 1.0000 - val_loss: 4.5253 - val_acc: 0.1320\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 104us/step - loss: 0.0072 - acc: 1.0000 - val_loss: 4.5437 - val_acc: 0.1312\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 103us/step - loss: 0.0067 - acc: 1.0000 - val_loss: 4.5588 - val_acc: 0.1304\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.04%\n",
      "Accuracy in Test: 73.60%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 109us/step - loss: 0.0063 - acc: 1.0000 - val_loss: 4.5749 - val_acc: 0.1312\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 103us/step - loss: 0.0059 - acc: 1.0000 - val_loss: 4.5921 - val_acc: 0.1312\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 110us/step - loss: 0.0056 - acc: 1.0000 - val_loss: 4.6083 - val_acc: 0.1320\n",
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 108us/step - loss: 0.0052 - acc: 1.0000 - val_loss: 4.6264 - val_acc: 0.1304\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 105us/step - loss: 0.0049 - acc: 1.0000 - val_loss: 4.6438 - val_acc: 0.1312\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.12%\n",
      "Accuracy in Test: 73.70%\n",
      "Train on 3750 samples, validate on 1250 samples\n",
      "Epoch 1/5\n",
      "3750/3750 [==============================] - 0s 102us/step - loss: 0.0046 - acc: 1.0000 - val_loss: 4.6601 - val_acc: 0.1304\n",
      "Epoch 2/5\n",
      "3750/3750 [==============================] - 0s 107us/step - loss: 0.0043 - acc: 1.0000 - val_loss: 4.6780 - val_acc: 0.1296\n",
      "Epoch 3/5\n",
      "3750/3750 [==============================] - 0s 103us/step - loss: 0.0041 - acc: 1.0000 - val_loss: 4.6944 - val_acc: 0.1312\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 4/5\n",
      "3750/3750 [==============================] - 0s 102us/step - loss: 0.0039 - acc: 1.0000 - val_loss: 4.7116 - val_acc: 0.1312\n",
      "Epoch 5/5\n",
      "3750/3750 [==============================] - 0s 103us/step - loss: 0.0036 - acc: 1.0000 - val_loss: 4.7293 - val_acc: 0.1320\n",
      "######## Model: mlp_2 ########\n",
      "Accuracy in Train: 100.00%\n",
      "Accuracy in Validation: 13.20%\n",
      "Accuracy in Test: 73.90%\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'test_significance' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-35-25aa9ff9d8f3>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      7\u001b[0m     \u001b[1;31m# evaluate_model(benchmark_models, train_data[ind], val_data[ind], test_data[ind])\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mmodel_results\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtrain_and_evaluate_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbenchmark_models\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mind\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 9\u001b[1;33m     \u001b[0mtest_pd\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_results\u001b[0m \u001b[1;33m(\u001b[0m\u001b[0mmodel_results\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     10\u001b[0m     \u001b[0mprint\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtest_pd\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-34-7cfc47ed1ed2>\u001b[0m in \u001b[0;36mtest_results\u001b[1;34m(model_results)\u001b[0m\n\u001b[0;32m      6\u001b[0m         \u001b[1;32mfor\u001b[0m \u001b[0mm2_key\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m             \u001b[0mcomp_model\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mmodel_results\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mm2_key\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m             \u001b[0mpv\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mtest_significance\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m      9\u001b[0m             \u001b[0mstatistic\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mp_value\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mstats\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mttest_ind\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mref_model\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcomp_model\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     10\u001b[0m             \u001b[0mcp_values\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mp_value\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'test_significance' is not defined"
     ]
    }
   ],
   "source": [
    "for ind, _ in enumerate (train_data):\n",
    "    print ((\"\").center(60, '_'))\n",
    "    print ((\"\").center(60, '#'))\n",
    "    print ((\" Dataset Index: \" + str(ind)+ \" \").center(60, '#'))\n",
    "    print ((\"\").center(60, '#'))\n",
    "    # train_model(benchmark_models, train_data[ind], val_data[ind])\n",
    "    # evaluate_model(benchmark_models, train_data[ind], val_data[ind], test_data[ind])\n",
    "    model_results = train_and_evaluate_model(benchmark_models, train_data[ind], val_data[ind], test_data[ind])\n",
    "    test_pd = test_results (model_results)\n",
    "    test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def test_significance(conf1, conf2, sig_level=0.05):\n",
    "    \"\"\"performs a statistical significance test on the passed lists, treating each list as coming from one distribution\n",
    "\n",
    "        Args:\n",
    "            conf1: list of first mse\n",
    "            conf2: list of second mse\n",
    "            sig_level: significance level to test for\n",
    "\n",
    "        Returns:\n",
    "            list of mse values from letting model run\n",
    "\n",
    "    \"\"\"\n",
    "    statistic, p_value = stats.ttest_ind(conf1,conf2)\n",
    "    if p_value<sig_level:\n",
    "        if statistic>0:\n",
    "            return conf2\n",
    "        else:\n",
    "            return conf1\n",
    "    else:\n",
    "        return False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "- Save outputs to file\n",
    "- Run each model multiple times to get statistical significance\n",
    "- Automatically test for statistical significances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\jonat\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in greater\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\jonat\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:879: RuntimeWarning: invalid value encountered in less\n",
      "  return (self.a < x) & (x < self.b)\n",
      "C:\\Users\\jonat\\Anaconda3\\lib\\site-packages\\scipy\\stats\\_distn_infrastructure.py:1818: RuntimeWarning: invalid value encountered in less_equal\n",
      "  cond2 = cond0 & (x <= self.a)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>rfe</th>\n",
       "      <th>xgbc</th>\n",
       "      <th>adb</th>\n",
       "      <th>gbc</th>\n",
       "      <th>lr</th>\n",
       "      <th>dtc</th>\n",
       "      <th>svm</th>\n",
       "      <th>mlp_0</th>\n",
       "      <th>mlp_1</th>\n",
       "      <th>mlp_2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>rfe</th>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>1.797128e-24</td>\n",
       "      <td>-6.067143e-24</td>\n",
       "      <td>8.260538e-24</td>\n",
       "      <td>1.934962e-25</td>\n",
       "      <td>-1.265404e-17</td>\n",
       "      <td>1.275433e-26</td>\n",
       "      <td>3.055909e-24</td>\n",
       "      <td>7.245837e-25</td>\n",
       "      <td>4.428094e-19</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>xgbc</th>\n",
       "      <td>-1.797128e-24</td>\n",
       "      <td>NaN</td>\n",
       "      <td>-0.000000e+00</td>\n",
       "      <td>-2.929703e-23</td>\n",
       "      <td>4.285574e-257</td>\n",
       "      <td>-1.142595e-26</td>\n",
       "      <td>6.140541e-264</td>\n",
       "      <td>2.299097e-12</td>\n",
       "      <td>8.784935e-17</td>\n",
       "      <td>3.869942e-05</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>adb</th>\n",
       "      <td>6.067143e-24</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>NaN</td>\n",
       "      <td>4.681320e-48</td>\n",
       "      <td>1.366934e-278</td>\n",
       "      <td>1.154758e-12</td>\n",
       "      <td>2.921167e-279</td>\n",
       "      <td>1.818783e-34</td>\n",
       "      <td>8.985480e-35</td>\n",
       "      <td>1.415555e-24</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>gbc</th>\n",
       "      <td>-8.260538e-24</td>\n",
       "      <td>2.929703e-23</td>\n",
       "      <td>-4.681320e-48</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>5.157499e-31</td>\n",
       "      <td>-2.827154e-26</td>\n",
       "      <td>5.919476e-36</td>\n",
       "      <td>4.431050e-16</td>\n",
       "      <td>4.389186e-19</td>\n",
       "      <td>1.099647e-07</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>lr</th>\n",
       "      <td>-1.934962e-25</td>\n",
       "      <td>-4.285574e-257</td>\n",
       "      <td>-1.366934e-278</td>\n",
       "      <td>-5.157499e-31</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.894083e-27</td>\n",
       "      <td>5.140132e-257</td>\n",
       "      <td>-5.945087e-02</td>\n",
       "      <td>1.263954e-09</td>\n",
       "      <td>8.375546e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>dtc</th>\n",
       "      <td>1.265404e-17</td>\n",
       "      <td>1.142595e-26</td>\n",
       "      <td>-1.154758e-12</td>\n",
       "      <td>2.827154e-26</td>\n",
       "      <td>2.894083e-27</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>4.968795e-28</td>\n",
       "      <td>1.805255e-26</td>\n",
       "      <td>7.225133e-27</td>\n",
       "      <td>3.061831e-22</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>svm</th>\n",
       "      <td>-1.275433e-26</td>\n",
       "      <td>-6.140541e-264</td>\n",
       "      <td>-2.921167e-279</td>\n",
       "      <td>-5.919476e-36</td>\n",
       "      <td>-5.140132e-257</td>\n",
       "      <td>-4.968795e-28</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-2.556793e-16</td>\n",
       "      <td>-2.049406e-11</td>\n",
       "      <td>-1.352906e-06</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_0</th>\n",
       "      <td>-3.055909e-24</td>\n",
       "      <td>-2.299097e-12</td>\n",
       "      <td>-1.818783e-34</td>\n",
       "      <td>-4.431050e-16</td>\n",
       "      <td>5.945087e-02</td>\n",
       "      <td>-1.805255e-26</td>\n",
       "      <td>2.556793e-16</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>2.101365e-08</td>\n",
       "      <td>4.680721e-01</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_1</th>\n",
       "      <td>-7.245837e-25</td>\n",
       "      <td>-8.784935e-17</td>\n",
       "      <td>-8.985480e-35</td>\n",
       "      <td>-4.389186e-19</td>\n",
       "      <td>-1.263954e-09</td>\n",
       "      <td>-7.225133e-27</td>\n",
       "      <td>2.049406e-11</td>\n",
       "      <td>-2.101365e-08</td>\n",
       "      <td>1.000000e+00</td>\n",
       "      <td>-1.032150e-02</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mlp_2</th>\n",
       "      <td>-4.428094e-19</td>\n",
       "      <td>-3.869942e-05</td>\n",
       "      <td>-1.415555e-24</td>\n",
       "      <td>-1.099647e-07</td>\n",
       "      <td>-8.375546e-01</td>\n",
       "      <td>-3.061831e-22</td>\n",
       "      <td>1.352906e-06</td>\n",
       "      <td>-4.680721e-01</td>\n",
       "      <td>1.032150e-02</td>\n",
       "      <td>1.000000e+00</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                rfe           xgbc            adb           gbc  \\\n",
       "rfe    1.000000e+00   1.797128e-24  -6.067143e-24  8.260538e-24   \n",
       "xgbc  -1.797128e-24            NaN  -0.000000e+00 -2.929703e-23   \n",
       "adb    6.067143e-24   0.000000e+00            NaN  4.681320e-48   \n",
       "gbc   -8.260538e-24   2.929703e-23  -4.681320e-48  1.000000e+00   \n",
       "lr    -1.934962e-25 -4.285574e-257 -1.366934e-278 -5.157499e-31   \n",
       "dtc    1.265404e-17   1.142595e-26  -1.154758e-12  2.827154e-26   \n",
       "svm   -1.275433e-26 -6.140541e-264 -2.921167e-279 -5.919476e-36   \n",
       "mlp_0 -3.055909e-24  -2.299097e-12  -1.818783e-34 -4.431050e-16   \n",
       "mlp_1 -7.245837e-25  -8.784935e-17  -8.985480e-35 -4.389186e-19   \n",
       "mlp_2 -4.428094e-19  -3.869942e-05  -1.415555e-24 -1.099647e-07   \n",
       "\n",
       "                  lr           dtc            svm         mlp_0         mlp_1  \\\n",
       "rfe     1.934962e-25 -1.265404e-17   1.275433e-26  3.055909e-24  7.245837e-25   \n",
       "xgbc   4.285574e-257 -1.142595e-26  6.140541e-264  2.299097e-12  8.784935e-17   \n",
       "adb    1.366934e-278  1.154758e-12  2.921167e-279  1.818783e-34  8.985480e-35   \n",
       "gbc     5.157499e-31 -2.827154e-26   5.919476e-36  4.431050e-16  4.389186e-19   \n",
       "lr      1.000000e+00 -2.894083e-27  5.140132e-257 -5.945087e-02  1.263954e-09   \n",
       "dtc     2.894083e-27  1.000000e+00   4.968795e-28  1.805255e-26  7.225133e-27   \n",
       "svm   -5.140132e-257 -4.968795e-28   1.000000e+00 -2.556793e-16 -2.049406e-11   \n",
       "mlp_0   5.945087e-02 -1.805255e-26   2.556793e-16  1.000000e+00  2.101365e-08   \n",
       "mlp_1  -1.263954e-09 -7.225133e-27   2.049406e-11 -2.101365e-08  1.000000e+00   \n",
       "mlp_2  -8.375546e-01 -3.061831e-22   1.352906e-06 -4.680721e-01  1.032150e-02   \n",
       "\n",
       "              mlp_2  \n",
       "rfe    4.428094e-19  \n",
       "xgbc   3.869942e-05  \n",
       "adb    1.415555e-24  \n",
       "gbc    1.099647e-07  \n",
       "lr     8.375546e-01  \n",
       "dtc    3.061831e-22  \n",
       "svm   -1.352906e-06  \n",
       "mlp_0  4.680721e-01  \n",
       "mlp_1 -1.032150e-02  \n",
       "mlp_2  1.000000e+00  "
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_pd = test_results (model_results)\n",
    "test_pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>adb</th>\n",
       "      <th>dtc</th>\n",
       "      <th>gbc</th>\n",
       "      <th>lr</th>\n",
       "      <th>mlp_0</th>\n",
       "      <th>mlp_1</th>\n",
       "      <th>mlp_2</th>\n",
       "      <th>rfe</th>\n",
       "      <th>svm</th>\n",
       "      <th>xgbc</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.386</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.523</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.397</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.722</td>\n",
       "      <td>0.752</td>\n",
       "      <td>0.726</td>\n",
       "      <td>0.520</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.383</td>\n",
       "      <td>0.689</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.735</td>\n",
       "      <td>0.529</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.405</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.729</td>\n",
       "      <td>0.749</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.509</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.404</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.724</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.508</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.380</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.744</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.518</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.389</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.730</td>\n",
       "      <td>0.743</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.512</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.378</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.734</td>\n",
       "      <td>0.746</td>\n",
       "      <td>0.736</td>\n",
       "      <td>0.521</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.388</td>\n",
       "      <td>0.690</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.732</td>\n",
       "      <td>0.738</td>\n",
       "      <td>0.737</td>\n",
       "      <td>0.507</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>0.339</td>\n",
       "      <td>0.391</td>\n",
       "      <td>0.691</td>\n",
       "      <td>0.73</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.751</td>\n",
       "      <td>0.739</td>\n",
       "      <td>0.511</td>\n",
       "      <td>0.765</td>\n",
       "      <td>0.705</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "     adb    dtc    gbc    lr  mlp_0  mlp_1  mlp_2    rfe    svm   xgbc\n",
       "0  0.339  0.386  0.690  0.73  0.722  0.744  0.689  0.523  0.765  0.705\n",
       "1  0.339  0.397  0.690  0.73  0.722  0.752  0.726  0.520  0.765  0.705\n",
       "2  0.339  0.383  0.689  0.73  0.730  0.743  0.735  0.529  0.765  0.705\n",
       "3  0.339  0.405  0.690  0.73  0.729  0.749  0.736  0.509  0.765  0.705\n",
       "4  0.339  0.404  0.691  0.73  0.724  0.743  0.737  0.508  0.765  0.705\n",
       "5  0.339  0.380  0.690  0.73  0.725  0.744  0.739  0.518  0.765  0.705\n",
       "6  0.339  0.389  0.691  0.73  0.730  0.743  0.736  0.512  0.765  0.705\n",
       "7  0.339  0.378  0.691  0.73  0.734  0.746  0.736  0.521  0.765  0.705\n",
       "8  0.339  0.388  0.690  0.73  0.732  0.738  0.737  0.507  0.765  0.705\n",
       "9  0.339  0.391  0.691  0.73  0.725  0.751  0.739  0.511  0.765  0.705"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.DataFrame(model_results)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
