Over the course of research on Convolutional Neural Network (CNN) architectures, little modifications have been done to the fully-connected layers at the end of the net- works. In image classification, these neural network layers are responsible for creating the final classification results based on the output of the last layer of high-level image filters. Before the breakthrough of CNNs, these image filters were handcrafted, and any classification algorithm was applied to their output. Because neural networks use gradients to learn their weights subject to the classification error, fully-connected neural networks are a natural choice for CNNs. But the question arises: Are fully- connected layers in a CNN superior to other classification algorithms? After the net- work is trained, the approach is to benchmark different classification algorithms on CNNs by removing the existing fully-connected classifier. Thus, the flattened output from the last convolutional layer is used as the input for multiple benchmark classi- fication algorithms.

The following notebooks are used to test the hypothesis.
