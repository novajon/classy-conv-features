{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #2\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/matplotlib/__init__.py:1067: UserWarning: Duplicate key in file \"/home/ubuntu/.config/matplotlib/matplotlibrc\", line #3\n",
      "  (fname, cnt))\n",
      "/home/ubuntu/anaconda3/lib/python3.6/site-packages/h5py/__init__.py:36: FutureWarning: Conversion of the second argument of issubdtype from `float` to `np.floating` is deprecated. In future, it will be treated as `np.float64 == np.dtype(float).type`.\n",
      "  from ._conv import register_converters as _register_converters\n",
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier, GradientBoostingClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import svm\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import GridSearchCV, train_test_split, KFold\n",
    "\n",
    "import keras\n",
    "from keras.utils import to_categorical\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Activation, Dropout\n",
    "\n",
    "from scipy import stats\n",
    "import glob\n",
    "import time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "training_src=[]\n",
    "test_src = []\n",
    "validation_src = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "file_list = glob.glob(\"data/intermediate/*.txt\")\n",
    "for file in file_list:\n",
    "    f_type = file.split(\"_pred_\")[-1].split(\"_\")[0]\n",
    "    if f_type == \"train\":\n",
    "        training_src.append(file)\n",
    "    elif f_type == \"val\":\n",
    "        validation_src.append(file)\n",
    "    elif f_type == \"test\":\n",
    "        test_src.append(file)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(src):\n",
    "    with open(src, 'r') as myfile:\n",
    "        data=myfile.read().replace('\\n', '')\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "def treat_data(data_string):\n",
    "    data_string = data_string.replace(\"]\", \"\")\n",
    "    data_string = data_string.replace(\" \", \"\")\n",
    "    data_split = data_string.split(\"[\")\n",
    "    data_split = [(d.split(\",\")) for d in data_split]\n",
    "    data_split_clean = [d[:-1] for d in data_split[:-1]]\n",
    "    data_split_clean.append(data_split[-1])\n",
    "    data_split_clean = [d for d in data_split_clean if d]\n",
    "    return data_split_clean"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_data(data):\n",
    "    inp = []\n",
    "    target = []\n",
    "    for d in data:\n",
    "        inp.append([float(x) for x in d[:-1]])\n",
    "        target.append(float(d[-1]))\n",
    "    inp = np.array(inp)\n",
    "    target = np.array(target)\n",
    "    return inp,target"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_source (src):\n",
    "    data_string = read_data(src)\n",
    "    data_split = treat_data(data_string)\n",
    "    return split_data(data_split)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(model, data):\n",
    "    y_pred = model.predict(data[0])\n",
    "    try: predictions = [round(value) for value in y_pred]\n",
    "    except: predictions = [np.argmax(value) for value in y_pred]\n",
    "    # evaluate predictions\n",
    "    d = {}\n",
    "    d[\"accuracy\"] = accuracy_score(data[1], predictions)\n",
    "    d[\"confusion matrix\"] = confusion_matrix(data[1], predictions)\n",
    "    d[\"precision\"] = precision_score(data[1], predictions, average='macro')\n",
    "    d[\"recall\"] = recall_score(data[1], predictions, average='macro')\n",
    "    d[\"f1-score\"] = f1_score(data[1], predictions, average='macro')\n",
    "    # d[\"roc-auc\"] = roc_auc_score(data[1], predictions, )\n",
    "    d[\"cohen's kappa\"] = cohen_kappa_score(data[1], predictions)\n",
    "    \n",
    "    return d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_measures(measure, data_type=\"data\", measure_name=\"Accuracy\"):\n",
    "    return \"%s in %s: %.2f\" % (measure_name, data_type, measure)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_measures(evaluation, t):\n",
    "    for key in evaluation.keys():\n",
    "        if key!=\"confusion matrix\":\n",
    "            print (get_measures(evaluation[key], t, key))\n",
    "        else:\n",
    "            print(key)\n",
    "            print(evaluation[key])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data_from_sources (training_src, test_src, validation_src=\"\"):\n",
    "    train = get_data_from_source(training_src)\n",
    "    test = get_data_from_source(test_src)\n",
    "    try:\n",
    "        if validation_src !=\"\":\n",
    "            val = get_data_from_source(validation_src)\n",
    "        else:\n",
    "            inp_test, inp_val, target_test, target_val = train_test_split(*test)\n",
    "            test = (inp_test, target_test)\n",
    "            val = (inp_val, target_val)\n",
    "    except: \n",
    "        inp_test, inp_val, target_test, target_val = train_test_split(*test)\n",
    "        test = (inp_test, target_test)\n",
    "        val = (inp_val, target_val)\n",
    "    return train, val, test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data = []\n",
    "test_data = []\n",
    "val_data = []\n",
    "\n",
    "ind = 0\n",
    "for ind, _ in enumerate(training_src):\n",
    "    if ind>=len(validation_src):\n",
    "        val_src = \"\"\n",
    "    else:\n",
    "        val_src = validation_src[ind]\n",
    "    train, val, test = get_data_from_sources(training_src[ind], test_src[ind], val_src)\n",
    "    train_data.append(train)\n",
    "    test_data.append(test)\n",
    "    val_data.append(val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_classes = int(max(train_data[0][1])+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlp_models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(1024, input_shape=(2048,)))\n",
    "model.add(Activation('elu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(512, input_shape=(2048,)))\n",
    "model.add(Activation('relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(num_classes))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(num_classes, input_shape=(2048,)))\n",
    "model.add(Activation('softmax'))\n",
    "\n",
    "model.compile(loss=keras.losses.categorical_crossentropy,\n",
    "              optimizer=keras.optimizers.Adam(lr=0.0001),\n",
    "              metrics=['accuracy'])\n",
    "\n",
    "mlp_models.append(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "epochs=50"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "svm_candidates = [\n",
    "  {'C': [1, 10, 100, 1000], 'kernel': ['linear']},\n",
    "  # {'C': [1, 10, 100, 1000], 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe_candidates = [\n",
    "  {'n_estimators': [10, 100, 1000], 'criterion': ['gini', \"entropy\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "adb_candidates = [\n",
    "  {'n_estimators': [10, 100, 1000], 'learning_rate': [1.0, 0.5, 0.1], 'algorithm':[\"SAMME.R\", \"SAMME\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "gbc_candidates = [\n",
    "  {'n_estimators': [10, 100, 1000], 'learning_rate': [0.05, 0.1, 0.5], 'criterion':[\"friedman_mse\", \"mae\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "lr_candidates= [\n",
    "    {'penalty': [\"l2\", \"l5\"]}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "dtc_candidates= [\n",
    "    {'criterion': [\"l1\", \"l2\"], 'splitter':['best']}\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "xgbc_candidates = [\n",
    "    {\n",
    "        'max_depth':[10], 'learning_rate':[0.1], 'n_estimators':[1000]     # objective, booster\n",
    "    }\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "parameter_candidates = {}\n",
    "parameter_candidates [\"svm\"] = svm_candidates\n",
    "parameter_candidates[\"rfe\"] = rfe_candidates\n",
    "parameter_candidates [\"adb\"] = adb_candidates\n",
    "parameter_candidates[\"gbc\"] = gbc_candidates\n",
    "parameter_candidates[\"lr\"] = lr_candidates\n",
    "parameter_candidates [\"dtc\"] = dtc_candidates\n",
    "parameter_candidates[\"xgbc\"] = xgbc_candidates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "rfe = RandomForestClassifier()\n",
    "adb = AdaBoostClassifier()\n",
    "gbc = GradientBoostingClassifier()\n",
    "lr = LogisticRegression()\n",
    "dtc = DecisionTreeClassifier()#\n",
    "xgbc = XGBClassifier()\n",
    "svc = svm.SVC()\n",
    "# Genetic Programming-based\n",
    "\n",
    "benchmark_models = {\"rfe\":rfe, \"xgbc\":xgbc, \"adb\":adb, \"gbc\":gbc, \"lr\":lr, \"dtc\":dtc, \"svm\":svc}\n",
    "# benchmark_models = {\"adb\":adb, \"gbc\":gbc, \"lr\":lr, \"dtc\":dtc, \"svm\":svc}\n",
    "for x in range(len(mlp_models)):\n",
    "    benchmark_models[\"mlp_{}\".format(x)] = mlp_models[x] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def grid_search_model(benchmark_models, parameter_candidates, train, val, test, folds = 4):\n",
    "    cv_results = {}\n",
    "    for model_key in benchmark_models.keys():\n",
    "        model = benchmark_models[model_key]\n",
    "        print ((\" Model: \" + str(model_key)+ \" \").center(30, '#'))\n",
    "        try:\n",
    "            clf = GridSearchCV(estimator=model, param_grid=parameter_candidates[model_key], n_jobs=-1, cv=folds)\n",
    "            clf.fit (*train, n_jobs=1)\n",
    "            model = clf.best_estimator_\n",
    "            cv_results[model_key] = clf.cv_results_\n",
    "        except ValueError:\n",
    "            try:\n",
    "                kf = KFold(n_splits=folds)\n",
    "                cv_results[model_key] = []\n",
    "                for train_index, test_index in kf.split(X,):\n",
    "                    X_train, X_test = train[0][train_index], train[0][test_index]\n",
    "                    y_train, y_test = train[1][train_index], train[1][test_index]\n",
    "                    history = model.fit(X_train, to_categorical(y_train), epochs = epochs, validation_data = (X_test, to_categorical(y_test)))\n",
    "                    train_res = model.evaluate(X_train, y=y_train)\n",
    "                    cv_results[model_key].append(train_res)\n",
    "                benchmark_models[model_key] = model\n",
    "            except:\n",
    "                print(\"Problem with input shape\")\n",
    "                continue\n",
    "        train_eval = evaluate(model, train)\n",
    "        val_eval = evaluate(model, val)\n",
    "        test_eval = evaluate(model, test)\n",
    "        print_measures(train_eval, \"Train\")\n",
    "        print_measures(val_eval, \"Validation\")\n",
    "        print_measures(test_eval, \"Test\")  \n",
    "\n",
    "        benchmark_models[model_key] = model\n",
    "    return benchmark_models, cv_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "######### Model: rfe #########\n"
     ]
    },
    {
     "ename": "JoblibTypeError",
     "evalue": "JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f2ae0a38540, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ubuntu.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f2ae0a38540, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ubuntu.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    416             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    417                                    finalizer=self._asyncgen_finalizer_hook)\n    418         try:\n    419             events._set_running_loop(self)\n    420             while True:\n--> 421                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    422                 if self._stopping:\n    423                     break\n    424         finally:\n    425             self._stopping = False\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1426                         logger.warning('Executing %s took %.3f seconds',\n   1427                                        _format_handle(handle), dt)\n   1428                 finally:\n   1429                     self._current_handle = None\n   1430             else:\n-> 1431                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...7f2a90ba4158>))>>\n   1432         handle = None  # Needed to break cycles when an exception occurs.\n   1433 \n   1434     def _set_coroutine_wrapper(self, enabled):\n   1435         try:\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle IOLoop._run_callback(functools.par...7f2a90ba4158>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x7f2a90ba4158>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x7f2a90ba4158>))\n    754         \"\"\"Runs a callback with error handling.\n    755 \n    756         For use in subclasses.\n    757         \"\"\"\n    758         try:\n--> 759             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x7f2a90ba4158>)\n    760             if ret is not None:\n    761                 from tornado import gen\n    762                 # Functions that return Futures typically swallow all\n    763                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 17, 13, 38, 41, 819727, tzinfo=tzlocal()), 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'session': '4257cce9c5714c5f8e5f74c06bc231bd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'4257cce9c5714c5f8e5f74c06bc231bd']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 17, 13, 38, 41, 819727, tzinfo=tzlocal()), 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'session': '4257cce9c5714c5f8e5f74c06bc231bd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'4257cce9c5714c5f8e5f74c06bc231bd'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 17, 13, 38, 41, 819727, tzinfo=tzlocal()), 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'session': '4257cce9c5714c5f8e5f74c06bc231bd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-29-9d758001814b>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f2a87b944e0, executi...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f2a90b9e4b0, file \"<ipython-input-29-9d758001814b>\", line 3>\n        result = <ExecutionResult object at 7f2a87b944e0, executi...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f2a90b9e4b0, file \"<ipython-input-29-9d758001814b>\", line 3>, result=<ExecutionResult object at 7f2a87b944e0, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f2a90b9e4b0, file \"<ipython-input-29-9d758001814b>\", line 3>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\n\\nfrom skl...\\n\\nfrom scipy import stats\\nimport glob\\nimport time', 'training_src=[]\\ntest_src = []\\nvalidation_src = []', 'file_list = glob.glob(\"data/intermediate/*.txt\")...f f_type == \"test\":\\n        test_src.append(file)', \"def read_data(src):\\n    with open(src, 'r') as m...a=myfile.read().replace('\\\\n', '')\\n    return data\", 'def treat_data(data_string):\\n    data_string = d...ata_split_clean if d]\\n    return data_split_clean', 'def split_data(data):\\n    inp = []\\n    target = ...  target = np.array(target)\\n    return inp,target', 'def get_data_from_source (src):\\n    data_string ...ta(data_string)\\n    return split_data(data_split)', 'def evaluate(model, data):\\n    y_pred = model.pr...ppa_score(data[1], predictions)\\n    \\n    return d', 'def get_measures(measure, data_type=\"data\", meas...in %s: %.2f\" % (measure_name, data_type, measure)', 'def print_measures(evaluation, t):\\n    for key i...    print(key)\\n            print(evaluation[key])', 'def get_data_from_sources (training_src, test_sr...(inp_val, target_val)\\n    return train, val, test', 'train_data = []\\ntest_data = []\\nval_data = []\\n\\nin...  test_data.append(test)\\n    val_data.append(val)', 'num_classes = int(max(train_data[0][1])+1)', 'mlp_models = []', \"model = Sequential()\\nmodel.add(Dense(1024, input...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(512, input_...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(num_classes...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", 'epochs=50', \"svm_candidates = [\\n  {'C': [1, 10, 100, 1000], '..., 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\\n]\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\n\\nfrom skl...\\n\\nfrom scipy import stats\\nimport glob\\nimport time', 'training_src=[]\\ntest_src = []\\nvalidation_src = []', 'file_list = glob.glob(\"data/intermediate/*.txt\")...f f_type == \"test\":\\n        test_src.append(file)', \"def read_data(src):\\n    with open(src, 'r') as m...a=myfile.read().replace('\\\\n', '')\\n    return data\", 'def treat_data(data_string):\\n    data_string = d...ata_split_clean if d]\\n    return data_split_clean', 'def split_data(data):\\n    inp = []\\n    target = ...  target = np.array(target)\\n    return inp,target', 'def get_data_from_source (src):\\n    data_string ...ta(data_string)\\n    return split_data(data_split)', 'def evaluate(model, data):\\n    y_pred = model.pr...ppa_score(data[1], predictions)\\n    \\n    return d', 'def get_measures(measure, data_type=\"data\", meas...in %s: %.2f\" % (measure_name, data_type, measure)', 'def print_measures(evaluation, t):\\n    for key i...    print(key)\\n            print(evaluation[key])', 'def get_data_from_sources (training_src, test_sr...(inp_val, target_val)\\n    return train, val, test', 'train_data = []\\ntest_data = []\\nval_data = []\\n\\nin...  test_data.append(test)\\n    val_data.append(val)', 'num_classes = int(max(train_data[0][1])+1)', 'mlp_models = []', \"model = Sequential()\\nmodel.add(Dense(1024, input...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(512, input_...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(num_classes...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", 'epochs=50', \"svm_candidates = [\\n  {'C': [1, 10, 100, 1000], '..., 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\\n]\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/home/ubuntu/Jonathan/Thesis/<ipython-input-29-9d758001814b> in <module>()\n      1 final_models = []\n      2 cv_results = []\n      3 for ind, _ in enumerate(train_data):\n----> 4     m,cv = grid_search_model(benchmark_models, parameter_candidates, train_data[ind], val_data[ind], test_data[ind])\n      5     final_models.append(m)\n      6     cv_results.append(cv)\n\n...........................................................................\n/home/ubuntu/Jonathan/Thesis/<ipython-input-28-a492041ce230> in grid_search_model(benchmark_models={'adb': AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), 'dtc': DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n            splitter='best'), 'gbc': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'lr': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'mlp_0': <keras.models.Sequential object>, 'mlp_1': <keras.models.Sequential object>, 'mlp_2': <keras.models.Sequential object>, 'rfe': RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 'svm': SVC(C=1.0, cache_size=200, class_weight=None, co...None, shrinking=True,\n  tol=0.001, verbose=False), 'xgbc': XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1)}, parameter_candidates={'adb': [{'algorithm': ['SAMME.R', 'SAMME'], 'learning_rate': [1.0, 0.5, 0.1], 'n_estimators': [10, 100, 1000]}], 'dtc': [{'criterion': ['l1', 'l2'], 'splitter': ['best']}], 'gbc': [{'criterion': ['friedman_mse', 'mae'], 'learning_rate': [0.05, 0.1, 0.5], 'n_estimators': [10, 100, 1000]}], 'lr': [{'penalty': ['l2', 'l5']}], 'rfe': [{'criterion': ['gini', 'entropy'], 'n_estimators': [10, 100, 1000]}], 'svm': [{'C': [1, 10, 100, 1000], 'kernel': ['linear']}], 'xgbc': [{'learning_rate': [0.1], 'max_depth': [10], 'n_estimators': [1000]}]}, train=(array([[0.        , 0.        , 0.62930661, ...,....., 0.        , 0.326969  ,\n        0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.])), val=(array([[-0.32306081,  1.24802506, -0.01195955, .... -0.99229425,\n        -0.99269837, -0.63715732]]), array([5., 7., 1., ..., 8., 1., 1.])), test=(array([[ 1.52768421,  2.63810492, -0.5276345 , ....  7.54001904,\n         0.76481014, -0.95799547]]), array([0., 8., 8., 4., 6., 9., 2., 7., 6., 0., 9... 1., 2., 0., 8., 8., 4., 3., 6., 4., 9., 3., 7.])), folds=4)\n      3     for model_key in benchmark_models.keys():\n      4         model = benchmark_models[model_key]\n      5         print ((\" Model: \" + str(model_key)+ \" \").center(30, '#'))\n      6         try:\n      7             clf = GridSearchCV(estimator=model, param_grid=parameter_candidates[model_key], n_jobs=-1, cv=folds)\n----> 8             clf.fit (*train, n_jobs=1)\n      9             model = clf.best_estimator_\n     10             cv_results[model_key] = clf.cv_results_\n     11         except ValueError:\n     12             try:\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=array([[0.        , 0.        , 0.62930661, ...,....., 0.        , 0.326969  ,\n        0.81680095]]), y=array([4., 7., 6., ..., 4., 6., 7.]), groups=None, **fit_params={'n_jobs': 1})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=4, random_state=None, shuffle=False)>\n        X = array([[0.        , 0.        , 0.62930661, ...,....., 0.        , 0.326969  ,\n        0.81680095]])\n        y = array([4., 7., 6., ..., 4., 6., 7.])\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Thu May 17 13:39:01 2018\nPID: 9548                   Python 3.6.4: /home/ubuntu/anaconda3/bin/python\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), y=array([4., 7., 6., ..., 4., 6., 7.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 821,  840,  841, ..., 3747, 3748, 3749]), test=array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), verbose=0, parameters={'criterion': 'gini', 'n_estimators': 10}, fit_params={'n_jobs': 1}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train = memmap([[0.        , 0.76128989, 0.45608887, ......., 0.        , 0.326969  ,\n         0.81680095]])\n        y_train = array([9., 9., 9., ..., 4., 6., 7.])\n        fit_params = {'n_jobs': 1}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\nTypeError: fit() got an unexpected keyword argument 'n_jobs'\n___________________________________________________________________________",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRemoteTraceback\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;31mRemoteTraceback\u001b[0m: \n\"\"\"\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 350, in __call__\n    return self.func(*args, **kwargs)\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in __call__\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\", line 131, in <listcomp>\n    return [func(*args, **kwargs) for func, args, kwargs in self.items]\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py\", line 458, in _fit_and_score\n    estimator.fit(X_train, y_train, **fit_params)\nTypeError: fit() got an unexpected keyword argument 'n_jobs'\n\nDuring handling of the above exception, another exception occurred:\n\nTraceback (most recent call last):\n  File \"/home/ubuntu/anaconda3/lib/python3.6/multiprocessing/pool.py\", line 119, in worker\n    result = (True, func(*args, **kwds))\n  File \"/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/_parallel_backends.py\", line 359, in __call__\n    raise TransportableException(text, e_type)\nsklearn.externals.joblib.my_exceptions.TransportableException: TransportableException\n___________________________________________________________________________\nTypeError                                          Thu May 17 13:39:01 2018\nPID: 9548                   Python 3.6.4: /home/ubuntu/anaconda3/bin/python\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), y=array([4., 7., 6., ..., 4., 6., 7.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 821,  840,  841, ..., 3747, 3748, 3749]), test=array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), verbose=0, parameters={'criterion': 'gini', 'n_estimators': 10}, fit_params={'n_jobs': 1}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train = memmap([[0.        , 0.76128989, 0.45608887, ......., 0.        , 0.326969  ,\n         0.81680095]])\n        y_train = array([9., 9., 9., ..., 4., 6., 7.])\n        fit_params = {'n_jobs': 1}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\nTypeError: fit() got an unexpected keyword argument 'n_jobs'\n___________________________________________________________________________\n\"\"\"",
      "\nThe above exception was the direct cause of the following exception:\n",
      "\u001b[0;31mTransportableException\u001b[0m                    Traceback (most recent call last)",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    698\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'supports_timeout'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 699\u001b[0;31m                     \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_output\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mjob\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtimeout\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    700\u001b[0m                 \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/multiprocessing/pool.py\u001b[0m in \u001b[0;36mget\u001b[0;34m(self, timeout)\u001b[0m\n\u001b[1;32m    643\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 644\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_value\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    645\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTransportableException\u001b[0m: TransportableException\n___________________________________________________________________________\nTypeError                                          Thu May 17 13:39:01 2018\nPID: 9548                   Python 3.6.4: /home/ubuntu/anaconda3/bin/python\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), y=array([4., 7., 6., ..., 4., 6., 7.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 821,  840,  841, ..., 3747, 3748, 3749]), test=array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), verbose=0, parameters={'criterion': 'gini', 'n_estimators': 10}, fit_params={'n_jobs': 1}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train = memmap([[0.        , 0.76128989, 0.45608887, ......., 0.        , 0.326969  ,\n         0.81680095]])\n        y_train = array([9., 9., 9., ..., 4., 6., 7.])\n        fit_params = {'n_jobs': 1}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\nTypeError: fit() got an unexpected keyword argument 'n_jobs'\n___________________________________________________________________________",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m                           Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-29-9d758001814b>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0mcv_results\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mind\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;32min\u001b[0m \u001b[0menumerate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrain_data\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m     \u001b[0mm\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mcv\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mgrid_search_model\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mbenchmark_models\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparameter_candidates\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtrain_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mval_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtest_data\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mind\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m     \u001b[0mfinal_models\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0mcv_results\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mcv\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-28-a492041ce230>\u001b[0m in \u001b[0;36mgrid_search_model\u001b[0;34m(benchmark_models, parameter_candidates, train, val, test, folds)\u001b[0m\n\u001b[1;32m      6\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m             \u001b[0mclf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mGridSearchCV\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mparam_grid\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mparameter_candidates\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mcv\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mfolds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 8\u001b[0;31m             \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      9\u001b[0m             \u001b[0mmodel\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbest_estimator_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m             \u001b[0mcv_results\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mmodel_key\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mclf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mcv_results_\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, groups, **fit_params)\u001b[0m\n\u001b[1;32m    637\u001b[0m                                   error_score=self.error_score)\n\u001b[1;32m    638\u001b[0m           for parameters, (train, test) in product(candidate_params,\n\u001b[0;32m--> 639\u001b[0;31m                                                    cv.split(X, y, groups)))\n\u001b[0m\u001b[1;32m    640\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    641\u001b[0m         \u001b[0;31m# if one choose to see train score, \"out\" will contain train score info\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, iterable)\u001b[0m\n\u001b[1;32m    787\u001b[0m                 \u001b[0;31m# consumption.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    788\u001b[0m                 \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 789\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mretrieve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    790\u001b[0m             \u001b[0;31m# Make sure that we get a last message telling us we are done\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    791\u001b[0m             \u001b[0melapsed_time\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_start_time\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py\u001b[0m in \u001b[0;36mretrieve\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    738\u001b[0m                     \u001b[0mexception\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mexception_type\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mreport\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    739\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 740\u001b[0;31m                     \u001b[0;32mraise\u001b[0m \u001b[0mexception\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    741\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    742\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mJoblibTypeError\u001b[0m: JoblibTypeError\n___________________________________________________________________________\nMultiprocessing exception:\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/runpy.py in _run_module_as_main(mod_name='ipykernel.__main__', alter_argv=1)\n    188         sys.exit(msg)\n    189     main_globals = sys.modules[\"__main__\"].__dict__\n    190     if alter_argv:\n    191         sys.argv[0] = mod_spec.origin\n    192     return _run_code(code, main_globals, None,\n--> 193                      \"__main__\", mod_spec)\n        mod_spec = ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py')\n    194 \n    195 def run_module(mod_name, init_globals=None,\n    196                run_name=None, alter_sys=False):\n    197     \"\"\"Execute a module's code without importing it\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/runpy.py in _run_code(code=<code object <module> at 0x7f2ae0a38540, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>, run_globals={'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ubuntu.../python3.6/site-packages/ipykernel/kernelapp.py'>}, init_globals=None, mod_name='__main__', mod_spec=ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), pkg_name='ipykernel', script_name=None)\n     80                        __cached__ = cached,\n     81                        __doc__ = None,\n     82                        __loader__ = loader,\n     83                        __package__ = pkg_name,\n     84                        __spec__ = mod_spec)\n---> 85     exec(code, run_globals)\n        code = <code object <module> at 0x7f2ae0a38540, file \"/...3.6/site-packages/ipykernel/__main__.py\", line 1>\n        run_globals = {'__annotations__': {}, '__builtins__': <module 'builtins' (built-in)>, '__cached__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__pycache__/__main__.cpython-36.pyc', '__doc__': None, '__file__': '/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py', '__loader__': <_frozen_importlib_external.SourceFileLoader object>, '__name__': '__main__', '__package__': 'ipykernel', '__spec__': ModuleSpec(name='ipykernel.__main__', loader=<_f...b/python3.6/site-packages/ipykernel/__main__.py'), 'app': <module 'ipykernel.kernelapp' from '/home/ubuntu.../python3.6/site-packages/ipykernel/kernelapp.py'>}\n     86     return run_globals\n     87 \n     88 def _run_module_code(code, init_globals=None,\n     89                     mod_name=None, mod_spec=None,\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/__main__.py in <module>()\n      1 if __name__ == '__main__':\n      2     from ipykernel import kernelapp as app\n----> 3     app.launch_new_instance()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/traitlets/config/application.py in launch_instance(cls=<class 'ipykernel.kernelapp.IPKernelApp'>, argv=None, **kwargs={})\n    653 \n    654         If a global instance already exists, this reinitializes and starts it\n    655         \"\"\"\n    656         app = cls.instance(**kwargs)\n    657         app.initialize(argv)\n--> 658         app.start()\n        app.start = <bound method IPKernelApp.start of <ipykernel.kernelapp.IPKernelApp object>>\n    659 \n    660 #-----------------------------------------------------------------------------\n    661 # utility functions, for convenience\n    662 #-----------------------------------------------------------------------------\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelapp.py in start(self=<ipykernel.kernelapp.IPKernelApp object>)\n    481         if self.poller is not None:\n    482             self.poller.start()\n    483         self.kernel.start()\n    484         self.io_loop = ioloop.IOLoop.current()\n    485         try:\n--> 486             self.io_loop.start()\n        self.io_loop.start = <bound method BaseAsyncIOLoop.start of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n    487         except KeyboardInterrupt:\n    488             pass\n    489 \n    490 launch_new_instance = IPKernelApp.launch_instance\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/platform/asyncio.py in start(self=<tornado.platform.asyncio.AsyncIOMainLoop object>)\n    122         except (RuntimeError, AssertionError):\n    123             old_loop = None\n    124         try:\n    125             self._setup_logging()\n    126             asyncio.set_event_loop(self.asyncio_loop)\n--> 127             self.asyncio_loop.run_forever()\n        self.asyncio_loop.run_forever = <bound method BaseEventLoop.run_forever of <_Uni...EventLoop running=True closed=False debug=False>>\n    128         finally:\n    129             asyncio.set_event_loop(old_loop)\n    130 \n    131     def stop(self):\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py in run_forever(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n    416             sys.set_asyncgen_hooks(firstiter=self._asyncgen_firstiter_hook,\n    417                                    finalizer=self._asyncgen_finalizer_hook)\n    418         try:\n    419             events._set_running_loop(self)\n    420             while True:\n--> 421                 self._run_once()\n        self._run_once = <bound method BaseEventLoop._run_once of <_UnixS...EventLoop running=True closed=False debug=False>>\n    422                 if self._stopping:\n    423                     break\n    424         finally:\n    425             self._stopping = False\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/asyncio/base_events.py in _run_once(self=<_UnixSelectorEventLoop running=True closed=False debug=False>)\n   1426                         logger.warning('Executing %s took %.3f seconds',\n   1427                                        _format_handle(handle), dt)\n   1428                 finally:\n   1429                     self._current_handle = None\n   1430             else:\n-> 1431                 handle._run()\n        handle._run = <bound method Handle._run of <Handle IOLoop._run_callback(functools.par...7f2a90ba4158>))>>\n   1432         handle = None  # Needed to break cycles when an exception occurs.\n   1433 \n   1434     def _set_coroutine_wrapper(self, enabled):\n   1435         try:\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/asyncio/events.py in _run(self=<Handle IOLoop._run_callback(functools.par...7f2a90ba4158>))>)\n    140             self._callback = None\n    141             self._args = None\n    142 \n    143     def _run(self):\n    144         try:\n--> 145             self._callback(*self._args)\n        self._callback = <bound method IOLoop._run_callback of <tornado.platform.asyncio.AsyncIOMainLoop object>>\n        self._args = (functools.partial(<function wrap.<locals>.null_wrapper at 0x7f2a90ba4158>),)\n    146         except Exception as exc:\n    147             cb = _format_callback_source(self._callback, self._args)\n    148             msg = 'Exception in callback {}'.format(cb)\n    149             context = {\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/ioloop.py in _run_callback(self=<tornado.platform.asyncio.AsyncIOMainLoop object>, callback=functools.partial(<function wrap.<locals>.null_wrapper at 0x7f2a90ba4158>))\n    754         \"\"\"Runs a callback with error handling.\n    755 \n    756         For use in subclasses.\n    757         \"\"\"\n    758         try:\n--> 759             ret = callback()\n        ret = undefined\n        callback = functools.partial(<function wrap.<locals>.null_wrapper at 0x7f2a90ba4158>)\n    760             if ret is not None:\n    761                 from tornado import gen\n    762                 # Functions that return Futures typically swallow all\n    763                 # exceptions and store them in the Future.  If a Future\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=(), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ()\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in <lambda>()\n    531             return\n    532 \n    533         if state & self.socket.events:\n    534             # events still exist that haven't been processed\n    535             # explicitly schedule handling to avoid missing events due to edge-triggered FDs\n--> 536             self.io_loop.add_callback(lambda : self._handle_events(self.socket, 0))\n    537 \n    538     def _init_io_state(self):\n    539         \"\"\"initialize the ioloop event handler\"\"\"\n    540         with stack_context.NullContext():\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_events(self=<zmq.eventloop.zmqstream.ZMQStream object>, fd=<zmq.sugar.socket.Socket object>, events=0)\n    445             return\n    446         zmq_events = self.socket.EVENTS\n    447         try:\n    448             # dispatch events:\n    449             if zmq_events & zmq.POLLIN and self.receiving():\n--> 450                 self._handle_recv()\n        self._handle_recv = <bound method ZMQStream._handle_recv of <zmq.eventloop.zmqstream.ZMQStream object>>\n    451                 if not self.socket:\n    452                     return\n    453             if zmq_events & zmq.POLLOUT and self.sending():\n    454                 self._handle_send()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _handle_recv(self=<zmq.eventloop.zmqstream.ZMQStream object>)\n    475             else:\n    476                 raise\n    477         else:\n    478             if self._recv_callback:\n    479                 callback = self._recv_callback\n--> 480                 self._run_callback(callback, msg)\n        self._run_callback = <bound method ZMQStream._run_callback of <zmq.eventloop.zmqstream.ZMQStream object>>\n        callback = <function wrap.<locals>.null_wrapper>\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    481         \n    482 \n    483     def _handle_send(self):\n    484         \"\"\"Handle a send event.\"\"\"\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/zmq/eventloop/zmqstream.py in _run_callback(self=<zmq.eventloop.zmqstream.ZMQStream object>, callback=<function wrap.<locals>.null_wrapper>, *args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    427         close our socket.\"\"\"\n    428         try:\n    429             # Use a NullContext to ensure that all StackContexts are run\n    430             # inside our blanket exception handler rather than outside.\n    431             with stack_context.NullContext():\n--> 432                 callback(*args, **kwargs)\n        callback = <function wrap.<locals>.null_wrapper>\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    433         except:\n    434             gen_log.error(\"Uncaught exception in ZMQStream callback\",\n    435                           exc_info=True)\n    436             # Re-raise the exception so that IOLoop.handle_callback_exception\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/tornado/stack_context.py in null_wrapper(*args=([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],), **kwargs={})\n    271         # Fast path when there are no active contexts.\n    272         def null_wrapper(*args, **kwargs):\n    273             try:\n    274                 current_state = _state.contexts\n    275                 _state.contexts = cap_contexts[0]\n--> 276                 return fn(*args, **kwargs)\n        args = ([<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>],)\n        kwargs = {}\n    277             finally:\n    278                 _state.contexts = current_state\n    279         null_wrapper._wrapped = True\n    280         return null_wrapper\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatcher(msg=[<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>])\n    278         if self.control_stream:\n    279             self.control_stream.on_recv(self.dispatch_control, copy=False)\n    280 \n    281         def make_dispatcher(stream):\n    282             def dispatcher(msg):\n--> 283                 return self.dispatch_shell(stream, msg)\n        msg = [<zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>, <zmq.sugar.frame.Frame object>]\n    284             return dispatcher\n    285 \n    286         for s in self.shell_streams:\n    287             s.on_recv(make_dispatcher(s), copy=False)\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in dispatch_shell(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, msg={'buffers': [], 'content': {'allow_stdin': True, 'code': 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 17, 13, 38, 41, 819727, tzinfo=tzlocal()), 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'session': '4257cce9c5714c5f8e5f74c06bc231bd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'parent_header': {}})\n    228             self.log.warn(\"Unknown message type: %r\", msg_type)\n    229         else:\n    230             self.log.debug(\"%s: %s\", msg_type, msg)\n    231             self.pre_handler_hook()\n    232             try:\n--> 233                 handler(stream, idents, msg)\n        handler = <bound method Kernel.execute_request of <ipykernel.ipkernel.IPythonKernel object>>\n        stream = <zmq.eventloop.zmqstream.ZMQStream object>\n        idents = [b'4257cce9c5714c5f8e5f74c06bc231bd']\n        msg = {'buffers': [], 'content': {'allow_stdin': True, 'code': 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 17, 13, 38, 41, 819727, tzinfo=tzlocal()), 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'session': '4257cce9c5714c5f8e5f74c06bc231bd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'parent_header': {}}\n    234             except Exception:\n    235                 self.log.error(\"Exception in message handler:\", exc_info=True)\n    236             finally:\n    237                 self.post_handler_hook()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/kernelbase.py in execute_request(self=<ipykernel.ipkernel.IPythonKernel object>, stream=<zmq.eventloop.zmqstream.ZMQStream object>, ident=[b'4257cce9c5714c5f8e5f74c06bc231bd'], parent={'buffers': [], 'content': {'allow_stdin': True, 'code': 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', 'silent': False, 'stop_on_error': True, 'store_history': True, 'user_expressions': {}}, 'header': {'date': datetime.datetime(2018, 5, 17, 13, 38, 41, 819727, tzinfo=tzlocal()), 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'session': '4257cce9c5714c5f8e5f74c06bc231bd', 'username': 'username', 'version': '5.2'}, 'metadata': {}, 'msg_id': 'b374909bdd044e228dbdeaea84c13ef7', 'msg_type': 'execute_request', 'parent_header': {}})\n    394         if not silent:\n    395             self.execution_count += 1\n    396             self._publish_execute_input(code, parent, self.execution_count)\n    397 \n    398         reply_content = self.do_execute(code, silent, store_history,\n--> 399                                         user_expressions, allow_stdin)\n        user_expressions = {}\n        allow_stdin = True\n    400 \n    401         # Flush output before sending the reply.\n    402         sys.stdout.flush()\n    403         sys.stderr.flush()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/ipkernel.py in do_execute(self=<ipykernel.ipkernel.IPythonKernel object>, code='final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', silent=False, store_history=True, user_expressions={}, allow_stdin=True)\n    203 \n    204         self._forward_input(allow_stdin)\n    205 \n    206         reply_content = {}\n    207         try:\n--> 208             res = shell.run_cell(code, store_history=store_history, silent=silent)\n        res = undefined\n        shell.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)'\n        store_history = True\n        silent = False\n    209         finally:\n    210             self._restore_input()\n    211 \n    212         if res.error_before_exec is not None:\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/ipykernel/zmqshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, *args=('final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)',), **kwargs={'silent': False, 'store_history': True})\n    532             )\n    533         self.payload_manager.write_payload(payload)\n    534 \n    535     def run_cell(self, *args, **kwargs):\n    536         self._last_traceback = None\n--> 537         return super(ZMQInteractiveShell, self).run_cell(*args, **kwargs)\n        self.run_cell = <bound method ZMQInteractiveShell.run_cell of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        args = ('final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)',)\n        kwargs = {'silent': False, 'store_history': True}\n    538 \n    539     def _showtraceback(self, etype, evalue, stb):\n    540         # try to preserve ordering of tracebacks and print statements\n    541         sys.stdout.flush()\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', store_history=True, silent=False, shell_futures=True)\n   2657         -------\n   2658         result : :class:`ExecutionResult`\n   2659         \"\"\"\n   2660         try:\n   2661             result = self._run_cell(\n-> 2662                 raw_cell, store_history, silent, shell_futures)\n        raw_cell = 'final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)'\n        store_history = True\n        silent = False\n        shell_futures = True\n   2663         finally:\n   2664             self.events.trigger('post_execute')\n   2665             if not silent:\n   2666                 self.events.trigger('post_run_cell', result)\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in _run_cell(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, raw_cell='final_models = []\\ncv_results = []\\nfor ind, _ in ... final_models.append(m)\\n    cv_results.append(cv)', store_history=True, silent=False, shell_futures=True)\n   2780                 self.displayhook.exec_result = result\n   2781 \n   2782                 # Execute the user code\n   2783                 interactivity = 'none' if silent else self.ast_node_interactivity\n   2784                 has_raised = self.run_ast_nodes(code_ast.body, cell_name,\n-> 2785                    interactivity=interactivity, compiler=compiler, result=result)\n        interactivity = 'last_expr'\n        compiler = <IPython.core.compilerop.CachingCompiler object>\n   2786                 \n   2787                 self.last_execution_succeeded = not has_raised\n   2788                 self.last_execution_result = result\n   2789 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_ast_nodes(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, nodelist=[<_ast.Assign object>, <_ast.Assign object>, <_ast.For object>], cell_name='<ipython-input-29-9d758001814b>', interactivity='none', compiler=<IPython.core.compilerop.CachingCompiler object>, result=<ExecutionResult object at 7f2a87b944e0, executi...rue silent=False shell_futures=True> result=None>)\n   2898 \n   2899         try:\n   2900             for i, node in enumerate(to_run_exec):\n   2901                 mod = ast.Module([node])\n   2902                 code = compiler(mod, cell_name, \"exec\")\n-> 2903                 if self.run_code(code, result):\n        self.run_code = <bound method InteractiveShell.run_code of <ipykernel.zmqshell.ZMQInteractiveShell object>>\n        code = <code object <module> at 0x7f2a90b9e4b0, file \"<ipython-input-29-9d758001814b>\", line 3>\n        result = <ExecutionResult object at 7f2a87b944e0, executi...rue silent=False shell_futures=True> result=None>\n   2904                     return True\n   2905 \n   2906             for i, node in enumerate(to_run_interactive):\n   2907                 mod = ast.Interactive([node])\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/IPython/core/interactiveshell.py in run_code(self=<ipykernel.zmqshell.ZMQInteractiveShell object>, code_obj=<code object <module> at 0x7f2a90b9e4b0, file \"<ipython-input-29-9d758001814b>\", line 3>, result=<ExecutionResult object at 7f2a87b944e0, executi...rue silent=False shell_futures=True> result=None>)\n   2958         outflag = True  # happens in more places, so it's easier as default\n   2959         try:\n   2960             try:\n   2961                 self.hooks.pre_run_code_hook()\n   2962                 #rprint('Running code', repr(code_obj)) # dbg\n-> 2963                 exec(code_obj, self.user_global_ns, self.user_ns)\n        code_obj = <code object <module> at 0x7f2a90b9e4b0, file \"<ipython-input-29-9d758001814b>\", line 3>\n        self.user_global_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\n\\nfrom skl...\\n\\nfrom scipy import stats\\nimport glob\\nimport time', 'training_src=[]\\ntest_src = []\\nvalidation_src = []', 'file_list = glob.glob(\"data/intermediate/*.txt\")...f f_type == \"test\":\\n        test_src.append(file)', \"def read_data(src):\\n    with open(src, 'r') as m...a=myfile.read().replace('\\\\n', '')\\n    return data\", 'def treat_data(data_string):\\n    data_string = d...ata_split_clean if d]\\n    return data_split_clean', 'def split_data(data):\\n    inp = []\\n    target = ...  target = np.array(target)\\n    return inp,target', 'def get_data_from_source (src):\\n    data_string ...ta(data_string)\\n    return split_data(data_split)', 'def evaluate(model, data):\\n    y_pred = model.pr...ppa_score(data[1], predictions)\\n    \\n    return d', 'def get_measures(measure, data_type=\"data\", meas...in %s: %.2f\" % (measure_name, data_type, measure)', 'def print_measures(evaluation, t):\\n    for key i...    print(key)\\n            print(evaluation[key])', 'def get_data_from_sources (training_src, test_sr...(inp_val, target_val)\\n    return train, val, test', 'train_data = []\\ntest_data = []\\nval_data = []\\n\\nin...  test_data.append(test)\\n    val_data.append(val)', 'num_classes = int(max(train_data[0][1])+1)', 'mlp_models = []', \"model = Sequential()\\nmodel.add(Dense(1024, input...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(512, input_...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(num_classes...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", 'epochs=50', \"svm_candidates = [\\n  {'C': [1, 10, 100, 1000], '..., 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\\n]\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n        self.user_ns = {'Activation': <class 'keras.layers.core.Activation'>, 'AdaBoostClassifier': <class 'sklearn.ensemble.weight_boosting.AdaBoostClassifier'>, 'DecisionTreeClassifier': <class 'sklearn.tree.tree.DecisionTreeClassifier'>, 'Dense': <class 'keras.layers.core.Dense'>, 'Dropout': <class 'keras.layers.core.Dropout'>, 'GradientBoostingClassifier': <class 'sklearn.ensemble.gradient_boosting.GradientBoostingClassifier'>, 'GridSearchCV': <class 'sklearn.model_selection._search.GridSearchCV'>, 'In': ['', 'import numpy as np\\nimport pandas as pd\\n\\nfrom skl...\\n\\nfrom scipy import stats\\nimport glob\\nimport time', 'training_src=[]\\ntest_src = []\\nvalidation_src = []', 'file_list = glob.glob(\"data/intermediate/*.txt\")...f f_type == \"test\":\\n        test_src.append(file)', \"def read_data(src):\\n    with open(src, 'r') as m...a=myfile.read().replace('\\\\n', '')\\n    return data\", 'def treat_data(data_string):\\n    data_string = d...ata_split_clean if d]\\n    return data_split_clean', 'def split_data(data):\\n    inp = []\\n    target = ...  target = np.array(target)\\n    return inp,target', 'def get_data_from_source (src):\\n    data_string ...ta(data_string)\\n    return split_data(data_split)', 'def evaluate(model, data):\\n    y_pred = model.pr...ppa_score(data[1], predictions)\\n    \\n    return d', 'def get_measures(measure, data_type=\"data\", meas...in %s: %.2f\" % (measure_name, data_type, measure)', 'def print_measures(evaluation, t):\\n    for key i...    print(key)\\n            print(evaluation[key])', 'def get_data_from_sources (training_src, test_sr...(inp_val, target_val)\\n    return train, val, test', 'train_data = []\\ntest_data = []\\nval_data = []\\n\\nin...  test_data.append(test)\\n    val_data.append(val)', 'num_classes = int(max(train_data[0][1])+1)', 'mlp_models = []', \"model = Sequential()\\nmodel.add(Dense(1024, input...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(512, input_...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", \"model = Sequential()\\nmodel.add(Dense(num_classes...  metrics=['accuracy'])\\n\\nmlp_models.append(model)\", 'epochs=50', \"svm_candidates = [\\n  {'C': [1, 10, 100, 1000], '..., 'gamma': [0.001, 0.0001], 'kernel': ['rbf']},\\n]\", ...], 'KFold': <class 'sklearn.model_selection._split.KFold'>, 'KNeighborsClassifier': <class 'sklearn.neighbors.classification.KNeighborsClassifier'>, ...}\n   2964             finally:\n   2965                 # Reset our crash handler in place\n   2966                 sys.excepthook = old_excepthook\n   2967         except SystemExit as e:\n\n...........................................................................\n/home/ubuntu/Jonathan/Thesis/<ipython-input-29-9d758001814b> in <module>()\n      1 final_models = []\n      2 cv_results = []\n      3 for ind, _ in enumerate(train_data):\n----> 4     m,cv = grid_search_model(benchmark_models, parameter_candidates, train_data[ind], val_data[ind], test_data[ind])\n      5     final_models.append(m)\n      6     cv_results.append(cv)\n\n...........................................................................\n/home/ubuntu/Jonathan/Thesis/<ipython-input-28-a492041ce230> in grid_search_model(benchmark_models={'adb': AdaBoostClassifier(algorithm='SAMME.R', base_est...ing_rate=1.0, n_estimators=50, random_state=None), 'dtc': DecisionTreeClassifier(class_weight=None, criter..., random_state=None,\n            splitter='best'), 'gbc': GradientBoostingClassifier(criterion='friedman_m...e=1.0, verbose=0,\n              warm_start=False), 'lr': LogisticRegression(C=1.0, class_weight=None, dua...ol=0.0001,\n          verbose=0, warm_start=False), 'mlp_0': <keras.models.Sequential object>, 'mlp_1': <keras.models.Sequential object>, 'mlp_2': <keras.models.Sequential object>, 'rfe': RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), 'svm': SVC(C=1.0, cache_size=200, class_weight=None, co...None, shrinking=True,\n  tol=0.001, verbose=False), 'xgbc': XGBClassifier(base_score=0.5, booster='gbtree', ...ht=1, seed=None,\n       silent=True, subsample=1)}, parameter_candidates={'adb': [{'algorithm': ['SAMME.R', 'SAMME'], 'learning_rate': [1.0, 0.5, 0.1], 'n_estimators': [10, 100, 1000]}], 'dtc': [{'criterion': ['l1', 'l2'], 'splitter': ['best']}], 'gbc': [{'criterion': ['friedman_mse', 'mae'], 'learning_rate': [0.05, 0.1, 0.5], 'n_estimators': [10, 100, 1000]}], 'lr': [{'penalty': ['l2', 'l5']}], 'rfe': [{'criterion': ['gini', 'entropy'], 'n_estimators': [10, 100, 1000]}], 'svm': [{'C': [1, 10, 100, 1000], 'kernel': ['linear']}], 'xgbc': [{'learning_rate': [0.1], 'max_depth': [10], 'n_estimators': [1000]}]}, train=(array([[0.        , 0.        , 0.62930661, ...,....., 0.        , 0.326969  ,\n        0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.])), val=(array([[-0.32306081,  1.24802506, -0.01195955, .... -0.99229425,\n        -0.99269837, -0.63715732]]), array([5., 7., 1., ..., 8., 1., 1.])), test=(array([[ 1.52768421,  2.63810492, -0.5276345 , ....  7.54001904,\n         0.76481014, -0.95799547]]), array([0., 8., 8., 4., 6., 9., 2., 7., 6., 0., 9... 1., 2., 0., 8., 8., 4., 3., 6., 4., 9., 3., 7.])), folds=4)\n      3     for model_key in benchmark_models.keys():\n      4         model = benchmark_models[model_key]\n      5         print ((\" Model: \" + str(model_key)+ \" \").center(30, '#'))\n      6         try:\n      7             clf = GridSearchCV(estimator=model, param_grid=parameter_candidates[model_key], n_jobs=-1, cv=folds)\n----> 8             clf.fit (*train, n_jobs=1)\n      9             model = clf.best_estimator_\n     10             cv_results[model_key] = clf.cv_results_\n     11         except ValueError:\n     12             try:\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_search.py in fit(self=GridSearchCV(cv=4, error_score='raise',\n       e...ain_score='warn',\n       scoring=None, verbose=0), X=array([[0.        , 0.        , 0.62930661, ...,....., 0.        , 0.326969  ,\n        0.81680095]]), y=array([4., 7., 6., ..., 4., 6., 7.]), groups=None, **fit_params={'n_jobs': 1})\n    634                                   return_train_score=self.return_train_score,\n    635                                   return_n_test_samples=True,\n    636                                   return_times=True, return_parameters=False,\n    637                                   error_score=self.error_score)\n    638           for parameters, (train, test) in product(candidate_params,\n--> 639                                                    cv.split(X, y, groups)))\n        cv.split = <bound method StratifiedKFold.split of Stratifie...ld(n_splits=4, random_state=None, shuffle=False)>\n        X = array([[0.        , 0.        , 0.62930661, ...,....., 0.        , 0.326969  ,\n        0.81680095]])\n        y = array([4., 7., 6., ..., 4., 6., 7.])\n        groups = None\n    640 \n    641         # if one choose to see train score, \"out\" will contain train score info\n    642         if self.return_train_score:\n    643             (train_score_dicts, test_score_dicts, test_sample_counts, fit_time,\n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=Parallel(n_jobs=-1), iterable=<generator object BaseSearchCV.fit.<locals>.<genexpr>>)\n    784             if pre_dispatch == \"all\" or n_jobs == 1:\n    785                 # The iterable was consumed all at once by the above for loop.\n    786                 # No need to wait for async callbacks to trigger to\n    787                 # consumption.\n    788                 self._iterating = False\n--> 789             self.retrieve()\n        self.retrieve = <bound method Parallel.retrieve of Parallel(n_jobs=-1)>\n    790             # Make sure that we get a last message telling us we are done\n    791             elapsed_time = time.time() - self._start_time\n    792             self._print('Done %3i out of %3i | elapsed: %s finished',\n    793                         (len(self._output), len(self._output),\n\n---------------------------------------------------------------------------\nSub-process traceback:\n---------------------------------------------------------------------------\nTypeError                                          Thu May 17 13:39:01 2018\nPID: 9548                   Python 3.6.4: /home/ubuntu/anaconda3/bin/python\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in __call__(self=<sklearn.externals.joblib.parallel.BatchedCalls object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        self.items = [(<function _fit_and_score>, (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10}), {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'})]\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/externals/joblib/parallel.py in <listcomp>(.0=<list_iterator object>)\n    126     def __init__(self, iterator_slice):\n    127         self.items = list(iterator_slice)\n    128         self._size = len(self.items)\n    129 \n    130     def __call__(self):\n--> 131         return [func(*args, **kwargs) for func, args, kwargs in self.items]\n        func = <function _fit_and_score>\n        args = (RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), array([4., 7., 6., ..., 4., 6., 7.]), {'score': <function _passthrough_scorer>}, array([ 821,  840,  841, ..., 3747, 3748, 3749]), array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), 0, {'criterion': 'gini', 'n_estimators': 10})\n        kwargs = {'error_score': 'raise', 'fit_params': {'n_jobs': 1}, 'return_n_test_samples': True, 'return_parameters': False, 'return_times': True, 'return_train_score': 'warn'}\n    132 \n    133     def __len__(self):\n    134         return self._size\n    135 \n\n...........................................................................\n/home/ubuntu/anaconda3/lib/python3.6/site-packages/sklearn/model_selection/_validation.py in _fit_and_score(estimator=RandomForestClassifier(bootstrap=True, class_wei...te=None, verbose=0,\n            warm_start=False), X=memmap([[0.        , 0.        , 0.62930661, ......., 0.        , 0.326969  ,\n         0.81680095]]), y=array([4., 7., 6., ..., 4., 6., 7.]), scorer={'score': <function _passthrough_scorer>}, train=array([ 821,  840,  841, ..., 3747, 3748, 3749]), test=array([   0,    1,    2,    3,    4,    5,    6,...       1022, 1033, 1036, 1043, 1048, 1052, 1058]), verbose=0, parameters={'criterion': 'gini', 'n_estimators': 10}, fit_params={'n_jobs': 1}, return_train_score='warn', return_parameters=False, return_n_test_samples=True, return_times=True, error_score='raise')\n    453 \n    454     try:\n    455         if y_train is None:\n    456             estimator.fit(X_train, **fit_params)\n    457         else:\n--> 458             estimator.fit(X_train, y_train, **fit_params)\n        estimator.fit = <bound method BaseForest.fit of RandomForestClas...e=None, verbose=0,\n            warm_start=False)>\n        X_train = memmap([[0.        , 0.76128989, 0.45608887, ......., 0.        , 0.326969  ,\n         0.81680095]])\n        y_train = array([9., 9., 9., ..., 4., 6., 7.])\n        fit_params = {'n_jobs': 1}\n    459 \n    460     except Exception as e:\n    461         # Note fit time as time until error\n    462         fit_time = time.time() - start_time\n\nTypeError: fit() got an unexpected keyword argument 'n_jobs'\n___________________________________________________________________________"
     ]
    }
   ],
   "source": [
    "final_models = []\n",
    "cv_results = []\n",
    "for ind, _ in enumerate(train_data):\n",
    "    m,cv = grid_search_model(benchmark_models, parameter_candidates, train_data[ind], val_data[ind], test_data[ind])\n",
    "    final_models.append(m)\n",
    "    cv_results.append(cv)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
